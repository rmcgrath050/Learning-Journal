##Building a Data driven Dashboard

Can you think of any metrics that could be tracked to provide valuable data-driven insights in your organisation
(these can be HR-related or something else)?

###Investigate Business principles againset elearning! 

1. Customer acquisition and retention rates
2. Sales productivity and revenue metrics
3. Compliance and risk management indicators
4. Employee certification and licensing data
5. Branch/office performance and efficiency metrics

 Additionally, it's crucial to consider industry best practices and benchmarks when selecting and analysing these metrics.


##The transition from small to big data
1. Overwhelming data: Simple tools and databases that once sufficed for data storage and analysis become inadequate.
2. Performance bottlenecks: Existing systems may struggle to process data efficiently, leading to delays and reduced productivity.
3. Missed opportunities: The inability to leverage data for predictive insights or to identify trends and patterns, which are crucial for strategic planning.


##The Characteristics of Data
--had some of my own notes to add from lecture here 

The 5 Vs of data offer a simple framework to grasp these fundamental attributes: 
volume, variety, velocity, veracity, and value

Velocity: Refers to the speed at which data is generated, collected, and processed.
Veracity: Refers to the reliability and accuracy of the data.


Byte > KiloByte > MegaByte > Gigabyte > petabyte > exabyte 



##Fundamentals of data

###Qualitative - text data
Binomial - yes/no, true/false
Nominal - colours, countries etc.
Ordinal - order data , such as size, (poor,good,average) 


###Quantitative
Discrete - number of things, people per household etc (Fixed data) 
Continuous - measured, (weight, height, temperature, time spent on task) 



##Sources of Open and Public Data
- Google's Dataset Search -datasetsearch.research.google.com
- Google Scholar - scholar.google.com
- Kaggle -www.kaggle.com



##Data Types
XML is a markup language for structuring and exchanging data between systems, promoting interoperability.
JSON is a lightweight, human-readable format for transmitting data between servers and web applications, enhancing user experiences and performance. 
CSV is a widely used format for storing tabular data, facilitating efficient financial management and reporting processes.


##Cloud computing standards
two prominent cloud computing standards: 

AWS:
Description: This framework provides for best practices in designing secure, high-performing cloud-based applications, ensuring operational excellence.
Impact: Many web applications, including social media platforms and e-commerce websites, rely on JSON for seamless communication.

Azure:
Description: This framework provides guidance for building reliable, secure, and cost-efficient cloud solutions on Microsoft Azure, focusing on security, performance, operational excellence, and cost optimisation.
Impact: Financial institutions often use CSV files for data integration and analysis.

In class Sam also mentioned OpenAPI. 

##Regulatory requirements
General Data Protection Regulations (GDPR) - GDPR is an EU regulation governing data privacy and consent,
ISO 27001 - ensuring the confidentiality, integrity, and availability of data and information assets.


Important technological standards for data engineering include data formats like JSON, CSV, XML, 
API standards like REST and OpenAPI Specification, and cloud computing standards like AWS Well-Architected Framework


##Data stewardship principles
Data quality - Ensuring accuracy and reliability for informed decision-making
Data governance - Establishing policies for managing data assets throughout their lifecycle
Data ethics - Adhering to ethical guidelines for responsible data usage


##Engineering best practices
Always think the worse case scenario for continuous improvement! 
Scability - Growing data
Reliability - Implementing redundancy and disaster recovery mechanisms
Secuirty - Encryption 
Data documentation - Understanding Data systems/data


Pandas (styled as pandas) is a software library written for the Python programming language for data manipulation and analysis. 


